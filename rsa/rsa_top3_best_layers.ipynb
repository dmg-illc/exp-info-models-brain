{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from src.paths import ROOT\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from src.fmri_rsa_utils import *\n",
    "from src.utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating RDMs for Exp features\n",
    "\n",
    "# experiential features\n",
    "exp_ftrs = pd.read_csv(ROOT / 'data/exp_features.csv')\n",
    "\n",
    "# organising exp arrays into a dict\n",
    "exp_dict = {exp_ftrs.iloc[i,0]: np.array(exp_ftrs.iloc[i,1:].tolist()) for i in range(len(exp_ftrs))}\n",
    "\n",
    "# distance matrices (1-cosine_similarity)\n",
    "s2_exp = pd.read_csv(ROOT / 'data/Study2_model_RSMs/Exp48_SOE320_sim_mat.csv')\n",
    "words_s2 = s2_exp.Word.tolist()\n",
    "\n",
    "# organising words from study 2 in a dedicated matrix\n",
    "s2_exp_mat = np.stack([exp_dict[word] for word in words_s2])\n",
    "\n",
    "# obtaining RDM\n",
    "exp_rdm2 = get_distance_vec(s2_exp_mat)\n",
    "\n",
    "set2_cat = pd.read_csv(ROOT / 'data/word_categories_2.csv')\n",
    "objects = ['animal', 'food', 'tool', 'vehicle']\n",
    "events = ['negative event', 'sound', 'social event', 'communication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading brain data into RDM\n",
    "brain_2 = get_fmri_rdm_study2_aggregated('semantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_results = open_json(ROOT / 'results/rsa/rsa_brain_set2_top3.json')\n",
    "exp48_results = open_json(ROOT / 'results/rsa/rsa_exp48_set2_top3.json')\n",
    "\n",
    "best_layers = open_json(ROOT / 'results/rsa/best_layers.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualised embeddings\n",
    "\n",
    "Here, we consider embeddings obtained from nouns plugged into neutral sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse_cont = pickle.load(open(ROOT / 'results/simcse/simcse_layers_context.pkl', 'rb'))\n",
    "mcse_cont = pickle.load(open(ROOT / 'results/mcse/mcse_layers_context.pkl', 'rb'))\n",
    "clap_cont = pickle.load(open(ROOT / 'results/clap/clap_layers_context.pkl', 'rb'))\n",
    "bert_cont = pickle.load(open(ROOT / 'results/bert/bert_layers_context.pkl', 'rb'))\n",
    "vbert_cont = pickle.load(open(ROOT / 'results/visualbert/visualbert_layers_context.pkl', 'rb'))\n",
    "clip_cont = pickle.load(open(ROOT / 'results/clip/clip_layers_context.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.22 0.0 True 0.52 True\n",
      "mcse 0.19 0.0 True 0.45 True\n",
      "clap 0.0 0.6967885380040464 False 0.03 True\n",
      "bert 0.23 0.0 True 0.53 True\n",
      "visualbert 0.12 4.795543045982238e-167 True 0.27 True\n",
      "clip 0.14 1.8609771360823958e-215 True 0.41 True\n"
     ]
    }
   ],
   "source": [
    "for model_embs, model_name in zip([simcse_cont, mcse_cont, clap_cont, bert_cont, vbert_cont, clip_cont], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    brain_rho, brain_pval = spearmanr(brain_rdm, brain_2)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    exp_rho, exp_pval = spearmanr(exp_rdm2, exp_rdm)\n",
    "    print(model_name, round(brain_rho, 2),brain_pval, brain_pval<0.05, round(exp_rho, 2), exp_pval<0.05)\n",
    "    \n",
    "    brain_results[model_name]['context']['set2'] = brain_rho\n",
    "    exp48_results[model_name]['context']['set2'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.14 0.42\n",
      "mcse 0.12 0.4\n",
      "clap 0.05 0.04\n",
      "bert 0.13 0.43\n",
      "visualbert 0.12 0.3\n",
      "clip 0.1 0.39\n"
     ]
    }
   ],
   "source": [
    "indices = np.where(set2_cat.category.isin(objects))[0]\n",
    "brain_data = get_fmri_rdm_study2_aggregated_subset('semantic', indices)\n",
    "exprdm = get_distance_vec(np.stack([exp_dict[word] for word in set2_cat.word[indices]]))\n",
    "\n",
    "for model_embs, model_name in zip([simcse_cont, mcse_cont, clap_cont, bert_cont, vbert_cont, clip_cont], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    brain_rho, _ = spearmanr(brain_rdm, brain_data)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp48_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    exp_rho, _ = spearmanr(exprdm, exp48_rdm)\n",
    "    print(model_name, round(brain_rho, 2), round(exp_rho, 2))\n",
    "    brain_results[model_name]['context']['objects'] = brain_rho\n",
    "    exp48_results[model_name]['context']['objects'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.22 0.54\n",
      "mcse 0.19 0.53\n",
      "clap -0.06 -0.0\n",
      "bert 0.27 0.52\n",
      "visualbert 0.08 0.25\n",
      "clip 0.18 0.48\n"
     ]
    }
   ],
   "source": [
    "indices = np.where(set2_cat.category.isin(events))[0]\n",
    "brain_data = get_fmri_rdm_study2_aggregated_subset('semantic', indices)\n",
    "exprdm = get_distance_vec(np.stack([exp_dict[word] for word in set2_cat.word[indices]]))\n",
    "\n",
    "for model_embs, model_name in zip([simcse_cont, mcse_cont, clap_cont, bert_cont, vbert_cont, clip_cont], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    brain_rho, _ = spearmanr(brain_rdm, brain_data)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp48_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    exp_rho, _ = spearmanr(exprdm, exp48_rdm)\n",
    "    print(model_name, round(brain_rho, 2), round(exp_rho, 2))\n",
    "    brain_results[model_name]['context']['events'] = brain_rho\n",
    "    exp48_results[model_name]['context']['events'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualised embeddings caption-like templates\n",
    "\n",
    "Here, we consider embeddings obtained from nouns plugged into caption-like sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse_cont_vis = pickle.load(open(ROOT / 'results/simcse/simcse_layers_visual_context_specific.pkl', 'rb'))\n",
    "mcse_cont_vis = pickle.load(open(ROOT / 'results/mcse/mcse_layers_visual_context_specific.pkl', 'rb'))\n",
    "clap_cont_vis = pickle.load(open(ROOT / 'results/clap/clap_layers_visual_context_specific.pkl', 'rb'))\n",
    "bert_cont_vis = pickle.load(open(ROOT / 'results/bert/bert_layers_visual_context_specific.pkl', 'rb'))\n",
    "vbert_cont_vis = pickle.load(open(ROOT / 'results/visualbert/visualbert_layers_visual_context_specific.pkl', 'rb'))\n",
    "clip_cont_vis = pickle.load(open(ROOT / 'results/clip/clip_layers_visual_context_specific.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.23 0.55\n",
      "mcse 0.2 0.5\n",
      "clap 0.1 0.22\n",
      "bert 0.26 0.59\n",
      "visualbert 0.14 0.3\n",
      "clip 0.15 0.47\n"
     ]
    }
   ],
   "source": [
    "for model_embs, model_name in zip([simcse_cont_vis, mcse_cont_vis, clap_cont_vis, bert_cont_vis, vbert_cont_vis, clip_cont_vis], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    brain_rho, _ = spearmanr(brain_rdm, brain_2)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    exp_rho, _ = spearmanr(exp_rdm2, exp_rdm)\n",
    "    print(model_name, round(brain_rho, 2), round(exp_rho, 2))\n",
    "    brain_results[model_name]['visual context']['set2'] = brain_rho\n",
    "    exp48_results[model_name]['visual context']['set2'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.12 0.46\n",
      "mcse 0.11 0.42\n",
      "clap 0.09 0.13\n",
      "bert 0.14 0.53\n",
      "visualbert 0.12 0.34\n",
      "clip 0.1 0.45\n"
     ]
    }
   ],
   "source": [
    "indices = np.where(set2_cat.category.isin(objects))[0]\n",
    "brain_data = get_fmri_rdm_study2_aggregated_subset('semantic', indices)\n",
    "exprdm = get_distance_vec(np.stack([exp_dict[word] for word in set2_cat.word[indices]]))\n",
    "\n",
    "for model_embs, model_name in zip([simcse_cont_vis, mcse_cont_vis, clap_cont_vis, bert_cont_vis, vbert_cont_vis, clip_cont_vis], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    brain_rho, _ = spearmanr(brain_rdm, brain_data)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    exp_rho, _ = spearmanr(exprdm, exp_rdm)\n",
    "    print(model_name, round(brain_rho, 2), round(exp_rho, 2))\n",
    "    brain_results[model_name]['visual context']['objects'] = brain_rho\n",
    "    exp48_results[model_name]['visual context']['objects'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.23 0.56\n",
      "mcse 0.21 0.58\n",
      "clap 0.06 0.21\n",
      "bert 0.27 0.57\n",
      "visualbert 0.1 0.27\n",
      "clip 0.19 0.52\n"
     ]
    }
   ],
   "source": [
    "indices = np.where(set2_cat.category.isin(events))[0]\n",
    "brain_data = get_fmri_rdm_study2_aggregated_subset('semantic', indices)\n",
    "exprdm = get_distance_vec(np.stack([exp_dict[word] for word in set2_cat.word[indices]]))\n",
    "\n",
    "for model_embs, model_name in zip([simcse_cont_vis, mcse_cont_vis, clap_cont_vis, bert_cont_vis, vbert_cont_vis, clip_cont_vis], ['simcse', 'mcse', 'clap', 'bert', 'visualbert', 'clip']):\n",
    "    avg_mat = average_representations_across_prompts(model_embs)\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    brain_rho, _ = spearmanr(brain_rdm, brain_data)\n",
    "\n",
    "    avg_mat_top3 = {word: avg_mat[word][np.array(best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in set2_cat.word])[indices, :])\n",
    "    exp_rho, _ = spearmanr(exprdm, exp_rdm)\n",
    "    print(model_name, round(brain_rho, 2), round(exp_rho, 2))\n",
    "    brain_results[model_name]['visual context']['events'] = brain_rho\n",
    "    exp48_results[model_name]['visual context']['events'] = exp_rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_json(brain_results, ROOT / 'results/rsa/rsa_brain_set2_top3.json')\n",
    "dict_to_json(exp48_results, ROOT / 'results/rsa/rsa_exp48_set2_top3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolated words\n",
    "\n",
    "Here, we're considering embeddings obtained by inputting the models with isolated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse = pickle.load(open(ROOT / 'results/simcse/simcse_layers.pkl', 'rb'))\n",
    "mcse = pickle.load(open(ROOT / 'results/mcse/mcse_bert_coco_layers.pkl', 'rb'))\n",
    "clap = pickle.load(open(ROOT / 'results/clap/clap_layers.pkl', 'rb'))\n",
    "clip = pickle.load(open(ROOT / 'results/clip/clip.pkl', 'rb'))\n",
    "bert = pickle.load(open(ROOT / 'results/bert/bert_layers.pkl', 'rb'))\n",
    "vbert = pickle.load(open(ROOT / 'results/visualbert/visualbert_layers.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_results_full = open_json(ROOT / 'results/rsa/rsa_brain_set2.json')\n",
    "exp48_results_full = open_json(ROOT / 'results/rsa/rsa_exp48_set2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_best_layers = {}\n",
    "for model_name in ['simcse', 'mcse','clap', 'bert', 'visualbert']:\n",
    "    new_best_layers[model_name] = {}\n",
    "  \n",
    "    best_model_layers = np.flip(np.argsort(brain_results_full[model_name]['non-contextualised']['set2']))\n",
    "    new_best_layers[model_name]['brain'] = best_model_layers[:3]\n",
    "\n",
    "    best_model_layers = np.flip(np.argsort(exp48_results_full[model_name]['non-contextualised']['set2']))\n",
    "    new_best_layers[model_name]['exp48'] = best_model_layers[:3]\n",
    "    # print(best_model_layers[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simcse': {'brain': array([11, 10, 12]), 'exp48': array([10,  8,  9])},\n",
       " 'mcse': {'brain': array([10,  9, 11]), 'exp48': array([ 9, 10,  8])},\n",
       " 'clap': {'brain': array([ 7,  8, 12]), 'exp48': array([12, 11, 10])},\n",
       " 'bert': {'brain': array([ 1, 11,  2]), 'exp48': array([ 1,  2, 10])},\n",
       " 'visualbert': {'brain': array([ 9, 10,  8]), 'exp48': array([ 9,  8, 10])}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_best_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse 0.18 0.0 True 0.29 True\n",
      "mcse 0.19 0.0 True 0.35 True\n",
      "clap 0.03 1.2888811514874077e-08 True 0.01 True\n",
      "bert 0.05 3.1106962922083e-32 True 0.16 True\n",
      "visualbert 0.09 8.387507311255873e-86 True 0.17 True\n"
     ]
    }
   ],
   "source": [
    "for model_embs, model_name in zip([simcse, mcse, clap, bert, vbert], ['simcse', 'mcse', 'clap', 'bert', 'visualbert']):\n",
    "    \n",
    "    avg_mat_top3 = {word: model_embs[word][np.array(new_best_layers[model_name]['brain']), :].mean(axis=0) for word in avg_mat}\n",
    "    brain_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    brain_rho, brain_pval = spearmanr(brain_rdm, brain_2)\n",
    "\n",
    "    avg_mat_top3 = {word: model_embs[word][np.array(new_best_layers[model_name]['exp48']), :].mean(axis=0) for word in avg_mat}\n",
    "    exp_rdm = get_distance_vec(np.stack([avg_mat_top3[word] for word in words_s2]))\n",
    "    exp_rho, exp_pval = spearmanr(exp_rdm2, exp_rdm)\n",
    "    print(model_name, round(brain_rho, 2),brain_pval, brain_pval<0.05, round(exp_rho, 2), exp_pval<0.05)\n",
    "    brain_results[model_name]['non-contextualised']['set2'] = brain_rho\n",
    "    exp48_results[model_name]['non-contextualised']['set2'] = exp_rho\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
