{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical tests\n",
    "\n",
    "This notebook contains code to replicate the statistical tests we conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr, norm\n",
    "from scipy.stats import ttest_rel\n",
    "from src.paths import ROOT\n",
    "from src.utils import * \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_significance_test(sample_size, corr1, corr2):\n",
    "    \n",
    "    # Fisher transformation\n",
    "    fisher1 = 0.5 * np.log((1 + corr1) / (1 - corr1))\n",
    "    fisher2 = 0.5 * np.log((1 + corr2) / (1 - corr2))\n",
    "    \n",
    "\n",
    "    expected_sd = np.sqrt(1.060 / (sample_size - 3))\n",
    "    \n",
    "    # Compute p-value\n",
    "    z_score = abs(fisher1 - fisher2) / expected_sd\n",
    "    p_value = 2 * (1 - norm.cdf(z_score))\n",
    "    \n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_results = open_json(ROOT / 'results/rsa/rsa_brain_set2_top3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects vs. Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 160\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'bert', 'visualbert']\n",
    "\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = brain_results[models[ind1]]['context']['objects']\n",
    "    corr2 = brain_results[models[ind2]]['context']['objects']\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    # t, p_val = ttest_rel()\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    corrected_pval = 0.05 / len(indices[0])\n",
    "    if p_val<corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse exp48 0.022933097110932055\n"
     ]
    }
   ],
   "source": [
    "n = 160\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'bert', 'visualbert']\n",
    "corrs = [brain_results[model]['context']['events'] for model in models] + [0.236]\n",
    "models = models + ['exp48']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = corrs[ind1]\n",
    "    corr2 = corrs[ind2]\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(indices[0])\n",
    "    if p_val>corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcse exp48 0.0006392325582973424\n",
      "mcse exp48 8.668658901811455e-09\n",
      "bert exp48 1.22432984976939e-05\n",
      "visualbert exp48 2.603060824668546e-07\n"
     ]
    }
   ],
   "source": [
    "n = 160\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'bert', 'visualbert']\n",
    "corrs = [brain_results[model]['context']['objects'] for model in models] + [0.169]\n",
    "models = models + ['exp48']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = corrs[ind1]\n",
    "    corr2 = corrs[ind2]\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(indices[0])\n",
    "    if p_val<corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 160\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'bert', 'visualbert']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "corr_events = [brain_results[model]['context']['events']for model in models] + [0.236]\n",
    "corr_objects = [brain_results[model]['context']['objects']for model in models] + [0.169]\n",
    "models += ['exp48']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    corr1 = corr_events[i]\n",
    "    corr2 = corr_objects[i]\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(models)\n",
    "    if p_val>corrected_pval:\n",
    "        print(model, p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 320\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'clap', 'bert', 'visualbert']\n",
    "corrs = [brain_results[model]['context']['set2'] for model in models] + [0.273]\n",
    "models = models + ['exp48']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = corrs[ind1]\n",
    "    corr2 = corrs[ind2]\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(indices[0])\n",
    "    if p_val>corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 320\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'bert', 'visualbert']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = brain_results[models[ind1]]['visual context']['set2']\n",
    "    corr2 = brain_results[models[ind2]]['visual context']['set2']\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(indices[0]+1)\n",
    "    if p_val>corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp48_results = open_json(ROOT / 'results/rsa/rsa_exp48_set2_top3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 320\n",
    "size = (n*n-n)/2\n",
    "models = ['simcse', 'mcse', 'clap', 'bert', 'visualbert']\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    corr1 = exp48_results[models[ind1]]['context']['set2']\n",
    "    corr2 = exp48_results[models[ind2]]['context']['set2']\n",
    "    p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "    corrected_pval = 0.05 / len(indices[0])\n",
    "    if p_val>corrected_pval:\n",
    "        print(models[ind1], models[ind2], p_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
